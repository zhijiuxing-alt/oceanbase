读写流程 
=========================



日志写 
------------

在执行 DML 操作时，为了保证事务性，会产生对应的 Redo Log，记录对数据行的插入、更新或删除操作，这些日志称之为 Clog。

OceanBase 数据库单台物理机上启动一个 observer 进程，有几万到十万分区，所有分区同时共用一个 Clog 文件，当写入的 Clog 文件超过配置的阈值（默认为 64 MB）时，会打开新的 Clog 文件进行写入。

OBServer 收到的某个分区 Leader 的写请求产生的 Clog、其他节点 OBServer 同步过来的 Clog（存在分区同在一个 Paxos Group)，都写入 Log Buffer 中，由单个 IO 线程批量刷入 Clog 文件。

写请求在分区 Leader 所在的 OBServer 上等待落盘，同时并行同步给其他 OBServer，多数派成功后返回 Client 成功。

![日志写.jpg](https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/1524125261/p184509.jpg "日志写.jpg")

数据写 
------------

与传统数据库的刷脏页机制不同，OceanBase 数据库的存储引擎基于 LSM Tree 架构，对于数据块的写主要是在转储和合并阶段。在 MEMTable 转储为 SSTable 时，也会在静态数据中记录当前的 Clog 日志回放点，在转储完成之后，对应 Clog 日志回放点之前的日志在理论上就可以被回收了，但通常这些日志文件并不会被立即删除，而是等到日志空间不足时再进行日志文件的重用。

在进行转储或合并时，对于一些较大的 SSTable，我们可能会将一个 SSTable 的数据拆分到多个线程中并行进行转储/合并，对于一张用户表，可以通过表级参数 tablet_size 来调整并行合并的粒度，当 SSTable 的大小超过表的 `tablet_size` 时，就会按照 `tablet_size` 对数据进行拆分，开启并行合并；但一般来说，并行合并的并行度不会超过配置的合并线程数。

查询流程 
-------------

对于数据查询，大体上可以分为以下这么几种：单点查询 Get、多点查询 MultiGet、单 Range 扫描、多 Range 扫描，以及对于插入操作需要处理的 Exist 查询。

Get/MultiGet/Exist 的查询流程是类似的，如下图所示。

![读写.jpg](https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/1524125261/p184510.jpg "读写.jpg")

Scan/MultiScan 的查询流程是类似的，如下图所示。

![读写2.jpg](https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/1524125261/p184511.jpg "读写2.jpg")
